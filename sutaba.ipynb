{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sutaba.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mpppk/colaboratory/blob/master/sutaba.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9W6D3jtL-PmK",
        "colab_type": "code",
        "outputId": "c8d5037f-a451-473d-d811-c7fb52f9bbd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# import tensorflow as tf\n",
        "# tf.test.gpu_device_name()\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yi6KAh2tExrV",
        "colab_type": "code",
        "outputId": "a3f1e8bc-174e-406c-8c45-1e2831d15011",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# !apt-get update && apt-get install imagemagick\n",
        "!cat /proc/uptime | awk '{print $1 /60 /60 /24 \"days (\" $1 \"sec)\"}'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.02971days (2566.94sec)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4f1ASW6_sqn",
        "colab_type": "code",
        "outputId": "8b2fd482-c962-4f28-dd7b-655466e3de75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import os\n",
        "from glob import glob\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input, Activation, Dropout, Flatten, Dense\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# 分類するクラス\n",
        "classes = [\"sutaba\",\"ramen\", \"other\"]\n",
        "nb_classes = len(classes)\n",
        "#画像の大きさを設定\n",
        "img_width, img_height = 224, 224\n",
        "\n",
        "# トレーニング用とバリデーション用の画像格納先（パスは自分で設定してください）\n",
        "base_path = \"/content/gdrive/My Drive/ColabNotebooks/sutaba\"\n",
        "train_data_dir = base_path + '/train'\n",
        "test_data_dir = base_path + '/test'\n",
        "aug_train_data_dir = base_path + '/aug_train'\n",
        "model_dir = base_path + '/models'\n",
        "# os.mkdir(aug_train_data_dir)\n",
        "\n",
        "#トレーニングデータ用の画像数\n",
        "def find_all_files(directory):\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            yield os.path.join(root, file)\n",
        "\n",
        "def count_file_num(p: str) -> int:\n",
        "  cnt = 0\n",
        "  for f in find_all_files(p):\n",
        "    cnt += 1\n",
        "  return cnt\n",
        "\n",
        "#バッチサイズ\n",
        "batch_size = 300\n",
        "#エポック数\n",
        "nb_epoch = 100\n",
        "validation_rate = 0.1\n",
        "\n",
        "sutaba_train_num = count_file_num(os.path.join(train_data_dir, classes[0]))\n",
        "ramen_train_num = count_file_num(os.path.join(train_data_dir, classes[1]))\n",
        "other_train_num = count_file_num(os.path.join(train_data_dir, classes[2]))\n",
        "class_weight = {0: other_train_num/sutaba_train_num, 1: other_train_num/ramen_train_num, 2: 1}\n",
        "nb_train_samples = sutaba_train_num + ramen_train_num + other_train_num\n",
        "\n",
        "sutaba_test_num = count_file_num(os.path.join(test_data_dir, classes[0]))\n",
        "ramen_test_num = count_file_num(os.path.join(test_data_dir, classes[1]))\n",
        "other_test_num = count_file_num(os.path.join(test_data_dir, classes[2]))\n",
        "nb_test_samples = sutaba_test_num + ramen_test_num + other_test_num\n",
        "\n",
        "print(sutaba_train_num, ramen_train_num, other_train_num, class_weight)\n",
        "print(sutaba_test_num, ramen_test_num, other_test_num)\n",
        "\n",
        "def get_latest_modified_file_path(dirname):\n",
        "  target = os.path.join(dirname, '*')\n",
        "  files = [(f, os.path.getmtime(f)) for f in glob(target)]\n",
        "  latest_modified_file_path = sorted(files, key=lambda files: files[1])[-1]\n",
        "  return latest_modified_file_path[0]\n",
        "\n",
        "def create_vgg16_from_weights(weights_path: str):\n",
        "  vgg16_model = create_vgg16()\n",
        "  vgg16_model.load_weights(get_latest_modified_file_path(weights_path))\n",
        "  return vgg16_model\n",
        "\n",
        "\n",
        "def create_vgg16():\n",
        "  # VGG16のロード。FC層は不要なので include_top=False\n",
        "  input_tensor = Input(shape=(img_width, img_height, 3))\n",
        "  vgg16 = VGG16(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "\n",
        "  # VGG16の図の緑色の部分（FC層）の作成\n",
        "  top_model = Sequential()\n",
        "  top_model.add(Flatten(input_shape=vgg16.output_shape[1:]))\n",
        "  top_model.add(Dense(256, activation='relu'))\n",
        "  top_model.add(Dropout(0.5))\n",
        "  top_model.add(Dense(nb_classes, activation='softmax'))\n",
        "\n",
        "  # VGG16とFC層を結合してモデルを作成（完成図が上の図）\n",
        "  # vgg_model = Model()\n",
        "  vgg_model = Model(input=vgg16.input, output=top_model(vgg16.output))\n",
        "\n",
        "  # VGG16の図の青色の部分は重みを固定（frozen）\n",
        "  for layer in vgg_model.layers[:15]:\n",
        "      layer.trainable = False\n",
        "\n",
        "  # 多クラス分類を指定\n",
        "  vgg_model.compile(loss='categorical_crossentropy',\n",
        "            optimizer=optimizers.SGD(lr=1e-3, momentum=0.9),\n",
        "            metrics=['accuracy'])\n",
        "  return vgg_model\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "  rescale=1.0 / 255,\n",
        "  #すでに画像の水増し済みの方は、下記２行は必要ありません。\n",
        "  zoom_range=0.2,\n",
        "  horizontal_flip=True,\n",
        "  validation_split=validation_rate\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "  train_data_dir,\n",
        "  target_size=(img_width, img_height),\n",
        "  color_mode='rgb',\n",
        "  classes=classes,\n",
        "  class_mode='categorical',\n",
        "  batch_size=batch_size,\n",
        "  # save_to_dir=aug_train_data_dir,\n",
        "  shuffle=True,\n",
        "  subset='training'\n",
        ")\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "  train_data_dir,\n",
        "  target_size=(img_width, img_height),\n",
        "  color_mode='rgb',\n",
        "  classes=classes,\n",
        "  class_mode='categorical',\n",
        "  batch_size=batch_size,\n",
        "  # save_to_dir=aug_train_data_dir,\n",
        "  shuffle=True,\n",
        "  subset='validation'\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "900 550 2387 {0: 2.652222222222222, 1: 4.34, 2: 1}\n",
            "73 67 70\n",
            "Found 3454 images belonging to 3 classes.\n",
            "Found 383 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "490F074Jtv0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mogrify \\\n",
        "  -path /content/gdrive/'My Drive'/ColabNotebooks/sutaba/train/sutaba \\\n",
        "  -define jpeg:size=224x224 \\\n",
        "  -thumbnail 224x224^ \\\n",
        "  -gravity center \\\n",
        "  -extent 224x224 \\\n",
        "  /content/gdrive/'My Drive'/ColabNotebooks/sutaba/train/sutaba-original/*.jpg\n",
        "# convert -define jpeg:size=200x200 original.jpeg  -thumbnail 100x100^ -gravity center -extent 100x100  thumbnail.jpeg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vn_8XIv2ARY8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "vgg_model = create_vgg16_from_weights(model_dir)\n",
        "n = datetime.datetime.now()\n",
        "nstr = f'{n.year}-{n.month:02}-{n.day:02}_{n.hour:02}-{n.minute:02}-{n.second:02}'\n",
        "fpath = base_path + f'/models/{nstr}' + 'weights.{epoch:02d}-{loss:.2f}-{acc:.2f}-{val_loss:.2f}-{val_acc:.2f}.hdf5'\n",
        "cp_cb = keras.callbacks.ModelCheckpoint(filepath=fpath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
        "# Fine-tuning\n",
        "history = vgg_model.fit_generator(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    # samples_per_epoch=nb_train_samples,\n",
        "    samples_per_epoch=len(train_generator.classes),\n",
        "    nb_epoch=nb_epoch,\n",
        "    callbacks=[cp_cb],\n",
        "    nb_val_samples=len(validation_generator.classes),\n",
        "    class_weight=class_weight\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvNEuXI9c9Wy",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_A140dojbEB1",
        "colab_type": "code",
        "outputId": "5526e92e-dab8-444e-b6b7-b1678151be49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "test_generator = test_datagen.flow_from_directory(\n",
        "  test_data_dir,\n",
        "  target_size=(img_width, img_height),\n",
        "  color_mode='rgb',\n",
        "  classes=classes,\n",
        "  class_mode='categorical',\n",
        "  batch_size=1,\n",
        "  shuffle=False)\n",
        "\n",
        "import pandas as pd\n",
        "vgg_model = create_vgg16_from_weights(model_dir)\n",
        "loss = vgg_model.predict_generator(test_generator, steps=len(test_generator.classes), verbose=1)\n",
        "prob = pd.DataFrame(loss, columns=classes)\n",
        "prob['predict'] = prob.idxmax(axis=1)\n",
        "prob['actual'] = [classes[c] for c in test_generator.classes]\n",
        "prob['path'] = test_generator.filenames\n",
        "prob.to_csv('results.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 210 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:84: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"se...)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "210/210 [==============================] - 78s 369ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "purjqCjhss1S",
        "colab_type": "code",
        "outputId": "e97fa9e4-42e2-4ad9-fea7-4eeda36204a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "mat = confusion_matrix(prob['actual'], prob['predict'], labels=classes)\n",
        "print(mat)\n",
        "\n",
        "t = prob['actual'] == 'ramen'\n",
        "p = prob['predict'] == 'ramen'\n",
        "print(confusion_matrix(t, p, labels=[True, False]))\n",
        "print('accuracy:', accuracy_score(t, p))\n",
        "print('precision:', precision_score(t, p))\n",
        "print('recall', recall_score(t, p))\n",
        "print('f1:', f1_score(t, p))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[66  1  6]\n",
            " [ 0 56 11]\n",
            " [ 2  4 64]]\n",
            "[[ 56  11]\n",
            " [  5 138]]\n",
            "accuracy: 0.9238095238095239\n",
            "precision: 0.9180327868852459\n",
            "recall 0.835820895522388\n",
            "f1: 0.875\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}